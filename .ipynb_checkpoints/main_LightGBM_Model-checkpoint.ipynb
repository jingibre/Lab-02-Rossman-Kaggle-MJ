{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Notebook Modelo LIGHTGBM Rossman Kaggle\n",
    "Disclaimer: los resultados que arroja la siguiente notebook corrida en anaconda son inferiores y distintos a los mostrados en kaggle porque esas corridas se realizaron en collab. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import de los modulos necesarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from pandas_summary import DataFrameSummary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data procesada utilizando las notebooks entregadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_feather('train_normalized_data.fth')\n",
    "df_test = pd.read_feather('test_normalized_data.fth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_vars = ['Store', 'DayOfWeek', 'Year', 'Month', 'Day', 'StateHoliday', 'CompetitionMonthsOpen', 'Promo2Weeks', \n",
    "            'StoreType', 'Assortment', 'PromoInterval', 'CompetitionOpenSinceYear', 'Promo2SinceYear', 'State', \n",
    "            'Week', 'Events', 'Promo_fw', 'Promo_bw', 'StateHoliday_bool_fw', 'StateHoliday_bool_bw', 'SchoolHoliday_fw', 'SchoolHoliday_bw']\n",
    "contin_vars = ['CompetitionDistance', \n",
    "               'Max_TemperatureC', 'Mean_TemperatureC', 'Min_TemperatureC', 'Precipitationmm',\n",
    "               'Max_Humidity', 'Mean_Humidity', 'Min_Humidity', 'Max_Wind_SpeedKm_h', \n",
    "               'Mean_Wind_SpeedKm_h', 'CloudCover', 'trend', 'trend_DE',\n",
    "               'AfterStateHoliday_bool', 'BeforeStateHoliday_bool', 'Promo', 'SchoolHoliday', 'StateHoliday_bool']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad en val: 30188, porcentaje: 0.9642465458145908\n"
     ]
    }
   ],
   "source": [
    "# Split data into train/val and define X and y variables\n",
    "df_train = df[df.Date < datetime.datetime(2015, 7, 1)]  \n",
    "df_val = df[df.Date >= datetime.datetime(2015, 7, 1)]\n",
    "print(f'Cantidad en val: {len(df_val)}, porcentaje: {len(df_train)/(len(df_train) + len(df_val))}')\n",
    "\n",
    "y_out_columns = ['Sales']\n",
    "X_train = df_train[cat_vars + contin_vars]\n",
    "X_val = df_val[cat_vars + contin_vars]\n",
    "X_test = df_test[cat_vars + contin_vars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((814150, 40), (30188, 40))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize output and determine wether to use log_output \n",
    "log_output = True\n",
    "    \n",
    "if log_output:\n",
    "    # Escala logaritmica\n",
    "    max_log_y = np.max(np.log(df[y_out_columns])).values\n",
    "    y_train = np.log(df_train[y_out_columns].values)/max_log_y\n",
    "    y_val = np.log(df_val[y_out_columns].values)/max_log_y\n",
    "else:\n",
    "    # Normalización\n",
    "    y_mean = df_train[y_out_columns].mean().values\n",
    "    y_std = df_train[y_out_columns].std().values\n",
    "    y_train = (df_train[y_out_columns].values - y_mean)/y_std\n",
    "    y_val = (df_val[y_out_columns].values - y_mean)/y_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data from hyper opt - Iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>loss</th>\n",
       "      <th>iteration</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>reg_lambda</th>\n",
       "      <th>num_leaves</th>\n",
       "      <th>n_estimators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>85</td>\n",
       "      <td>0.113355</td>\n",
       "      <td>85</td>\n",
       "      <td>560.0</td>\n",
       "      <td>0.051204</td>\n",
       "      <td>4.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>1200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>77</td>\n",
       "      <td>0.114225</td>\n",
       "      <td>77</td>\n",
       "      <td>600.0</td>\n",
       "      <td>0.042213</td>\n",
       "      <td>1.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>1200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>75</td>\n",
       "      <td>0.114354</td>\n",
       "      <td>75</td>\n",
       "      <td>600.0</td>\n",
       "      <td>0.042159</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>66</td>\n",
       "      <td>0.114421</td>\n",
       "      <td>66</td>\n",
       "      <td>540.0</td>\n",
       "      <td>0.043883</td>\n",
       "      <td>8.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>40</td>\n",
       "      <td>0.114514</td>\n",
       "      <td>40</td>\n",
       "      <td>600.0</td>\n",
       "      <td>0.049882</td>\n",
       "      <td>35.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>1200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>94</td>\n",
       "      <td>0.123523</td>\n",
       "      <td>94</td>\n",
       "      <td>560.0</td>\n",
       "      <td>0.019405</td>\n",
       "      <td>7.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>1200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.123810</td>\n",
       "      <td>13</td>\n",
       "      <td>540.0</td>\n",
       "      <td>0.027497</td>\n",
       "      <td>3.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>50</td>\n",
       "      <td>0.123960</td>\n",
       "      <td>50</td>\n",
       "      <td>580.0</td>\n",
       "      <td>0.021003</td>\n",
       "      <td>25.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35</td>\n",
       "      <td>0.124580</td>\n",
       "      <td>35</td>\n",
       "      <td>600.0</td>\n",
       "      <td>0.022498</td>\n",
       "      <td>28.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>1150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>0.125300</td>\n",
       "      <td>22</td>\n",
       "      <td>560.0</td>\n",
       "      <td>0.018558</td>\n",
       "      <td>27.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1150.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0      loss  iteration  max_depth  learning_rate  reg_lambda  \\\n",
       "85          85  0.113355         85      560.0       0.051204         4.0   \n",
       "77          77  0.114225         77      600.0       0.042213         1.0   \n",
       "75          75  0.114354         75      600.0       0.042159         1.0   \n",
       "66          66  0.114421         66      540.0       0.043883         8.0   \n",
       "40          40  0.114514         40      600.0       0.049882        35.0   \n",
       "..         ...       ...        ...        ...            ...         ...   \n",
       "94          94  0.123523         94      560.0       0.019405         7.0   \n",
       "13          13  0.123810         13      540.0       0.027497         3.0   \n",
       "50          50  0.123960         50      580.0       0.021003        25.0   \n",
       "35          35  0.124580         35      600.0       0.022498        28.0   \n",
       "22          22  0.125300         22      560.0       0.018558        27.0   \n",
       "\n",
       "    num_leaves  n_estimators  \n",
       "85        55.0        1200.0  \n",
       "77        65.0        1200.0  \n",
       "75        60.0        1200.0  \n",
       "66        60.0        1150.0  \n",
       "40        65.0        1200.0  \n",
       "..         ...           ...  \n",
       "94        55.0        1200.0  \n",
       "13        50.0        1000.0  \n",
       "50        75.0        1150.0  \n",
       "35        65.0        1150.0  \n",
       "22        50.0        1150.0  \n",
       "\n",
       "[100 rows x 8 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iterations_from_hyperopt = pd.read_csv('hyper_opt_iterations.csv')\n",
    "iterations_from_hyperopt.sort_values('loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0         85.000000\n",
       "loss                0.113355\n",
       "iteration          85.000000\n",
       "max_depth         560.000000\n",
       "learning_rate       0.051204\n",
       "reg_lambda          4.000000\n",
       "num_leaves         55.000000\n",
       "n_estimators     1200.000000\n",
       "Name: 85, dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We print the best parameters found\n",
    "iterations_from_hyperopt.loc[85,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightgbm\n",
      "  Downloading lightgbm-3.2.1-py3-none-win_amd64.whl (1.0 MB)\n",
      "Requirement already satisfied: wheel in c:\\users\\manny\\anaconda3\\lib\\site-packages (from lightgbm) (0.36.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\manny\\anaconda3\\lib\\site-packages (from lightgbm) (1.6.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\manny\\anaconda3\\lib\\site-packages (from lightgbm) (1.19.5)\n",
      "Requirement already satisfied: scikit-learn!=0.22.0 in c:\\users\\manny\\anaconda3\\lib\\site-packages (from lightgbm) (0.23.1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\manny\\anaconda3\\lib\\site-packages (from scikit-learn!=0.22.0->lightgbm) (0.16.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\manny\\anaconda3\\lib\\site-packages (from scikit-learn!=0.22.0->lightgbm) (2.1.0)\n",
      "Installing collected packages: lightgbm\n",
      "Successfully installed lightgbm-3.2.1\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Los valores presentados a continuación son los finales que entregan el mejor score privado en la competencia.\n",
    "# Son una modificación a mano de los parametros que entregó el optimizador. \n",
    "# Las modificaciones fueron para regularizar: subir el reg_lambda, bajar los n_estimators y subir el LR, etc.\n",
    "min_child_samples=5\n",
    "n_estimators=1000\n",
    "learning_rate=0.0516\n",
    "max_depth = 500\n",
    "num_leaves=53\n",
    "min_child_samples= 200 #194\n",
    "reg_lambda=10 #20 #10 #0.000000\n",
    "reg_alpha=1.000000\n",
    "colsample_bytree=0.519264\n",
    "min_child_weight=0.000000\n",
    "n_estimators=1000\n",
    "\n",
    "model = LGBMRegressor(min_child_samples=min_child_samples, n_estimators=n_estimators, learning_rate=learning_rate, max_depth=max_depth, num_leaves=num_leaves, reg_lambda=reg_lambda,\n",
    "                     reg_alpha=reg_alpha, colsample_bytree=colsample_bytree, min_child_weight=min_child_weight,n_jobs=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit params\n",
    "fit_params={\"early_stopping_rounds\":100, \n",
    "            \"eval_metric\" : 'l2', \n",
    "            \"eval_set\" : [(X_val, y_val.reshape(-1))],\n",
    "            'eval_names': ['valid'],\n",
    "            'verbose': 100,\n",
    "            'feature_name': 'auto', # that's actually the default\n",
    "            'categorical_feature': cat_vars\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\manny\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1702: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n",
      "C:\\Users\\manny\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1705: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is ['Assortment', 'CompetitionMonthsOpen', 'CompetitionOpenSinceYear', 'Day', 'DayOfWeek', 'Events', 'Month', 'Promo2SinceYear', 'Promo2Weeks', 'PromoInterval', 'Promo_bw', 'Promo_fw', 'SchoolHoliday_bw', 'SchoolHoliday_fw', 'State', 'StateHoliday', 'StateHoliday_bool_bw', 'StateHoliday_bool_fw', 'Store', 'StoreType', 'Week', 'Year']\n",
      "  _log_warning('categorical_feature in Dataset is overridden.\\n'\n",
      "C:\\Users\\manny\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1433: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "C:\\Users\\manny\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1245: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's l2: 0.000205226\n",
      "[200]\tvalid's l2: 0.000155032\n",
      "[300]\tvalid's l2: 0.000140838\n",
      "[400]\tvalid's l2: 0.000131015\n",
      "[500]\tvalid's l2: 0.000122887\n",
      "[600]\tvalid's l2: 0.000118858\n",
      "[700]\tvalid's l2: 0.000116199\n",
      "[800]\tvalid's l2: 0.000114703\n",
      "[900]\tvalid's l2: 0.000112284\n",
      "[1000]\tvalid's l2: 0.000110523\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid's l2: 0.000110523\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(colsample_bytree=0.519264, learning_rate=0.0516, max_depth=500,\n",
       "              min_child_samples=200, min_child_weight=0.0, n_estimators=1000,\n",
       "              n_jobs=8, num_leaves=53, reg_alpha=1.0, reg_lambda=10)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit model\n",
    "model.fit(X_train, y_train.reshape(-1), **fit_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analisis de los resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\textrm{RMSE} = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} \\left(\\frac{\\hat{y}_i - y_i}{y_i}\\right)^2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No sacamos lo de train para acelerar la notebook.\n",
    "if log_output:\n",
    "    #y_pred_train = np.exp(model.predict(X_train, verbose=1)*max_log_y)\n",
    "    y_pred = np.exp(model.predict(X_val, verbose=1)*max_log_y)\n",
    "    y_pred_test = np.exp(model.predict(X_test, verbose=1)*max_log_y)\n",
    "else:\n",
    "    #y_pred_train = model.predict(X_train, verbose=1)*y_std + y_mean\n",
    "    y_pred = model.predict(X_val, verbose=1)*y_std + y_mean\n",
    "    y_pred_test = model.predict(X_test, verbose=1)*y_std + y_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12002938035846607\n"
     ]
    }
   ],
   "source": [
    "# Validación\n",
    "val_score = np.sqrt((((df_val['Sales'].values - y_pred)/df_val['Sales'].values)**2).sum()/len(y_pred))\n",
    "print(val_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit a la competencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_csv = pd.read_csv('sample_submission.csv')\n",
    "sample_csv['Sales'] = y_pred_test\n",
    "sample_csv.head()\n",
    "\n",
    "sample_csv.to_csv(f'submision_lightgbm_{log_output}-{min_child_samples}-{n_estimators}-{learning_rate}-SCORE-{val_score}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
